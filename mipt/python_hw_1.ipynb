{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "Входные данные: строка target_word = 'князь'. Итак, начнём! Для начала посчитаем частоту использования отдельных слов в произведении. Для решения задачи воспользуемся уже знакомым нам словарём. Задание. Напишите программу, которая переберет все слова и занесет их в словарь word_counts . Увеличивайте счётчик при добавлении каждого нового слова, чтобы посчитать, сколько раз это слово встречается в тексте. Подсказка. Напоминаем, что метод get поможет проверить, какое значение соответствует ключу (слову) в словаре. Например, words.get(word, 0) вернёт либо значение из словаря, либо (0), если соответствующее слово пока отсутствует.\n",
    "\n",
    "Не забудьте добавить в начало своего кода функцию для чтения текста произведения:\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "В качестве результата выведите, сколько раз слово target_word было найдено в тексте. Например, для target_word = 'князь' ответ будет (1289)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Введите свое решение ниже\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "target_word = 'князь'\n",
    "\n",
    "def find_word_counts(data, target_word):\n",
    "    word_counts = {}\n",
    "\n",
    "    for item in data:\n",
    "        if item.isalpha():\n",
    "            if item not in word_counts:\n",
    "                word_counts[item] = 1\n",
    "            else:\n",
    "                word_counts[item] += 1\n",
    "               \n",
    "    return word_counts[target_word]\n",
    "\n",
    "print(find_word_counts(data, target_word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "\n",
    "target_word = 'князь'\n",
    "\n",
    "word_counts = {}\n",
    "for word in data:\n",
    "    word_counts[word] = word_counts.get(word, 0) + 1\n",
    "print(word_counts[target_word])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "Входные данные: строка target_word = 'человек'. Пришло время познакомиться с понятием document frequency. Document frequency (для удобства сократим до df) — это доля документов, в которых встречается искомое слово. В нашем случае речь идёт не о документах, а о главах книги (выше мы писали, что в текстовом документе главы разделяются строкой '[new chapter]'). Задание. Напишите программу, которая посчитает document frequency для заданного слова target_word и выведите результат на экран.\n",
    "\n",
    "Подсказка. Вычислить df можно по формуле: number_of_documents_with_target_word / number_of_documents number_of_documents — общее количество глав number_of_documents_with_target_word — количество глав, в которых встречается target_word\n",
    "\n",
    "Объясним на примере: наш текст состоит из (171) главы (number_of_documents), а слово человек встречается в (115) главах (number_of_documents_with_target_word). df слова человек = (115 / 171 = 0.672514619883041).\n",
    "\n",
    "Не забудьте добавить в начало своего кода функцию для чтения текста произведения:\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "target_word = 'человек'\n",
    "\n",
    "\n",
    "def find_document_frequency(data, target_word):\n",
    "    df, chapter_count = {}, 0\n",
    "    chapter = {}\n",
    "    for item  in data + ['[new chapter]']:\n",
    "        if item == '[new chapter]':\n",
    "            chapter = {}\n",
    "            chapter_count += 1\n",
    "         \n",
    "        if item not in chapter:\n",
    "            chapter[item] = 1\n",
    "            df[item] = df.get(item, 0) + 1\n",
    "            \n",
    "        else:\n",
    "            chapter[item] += 1\n",
    "            \n",
    "    \n",
    "    return df[target_word] / chapter_count\n",
    "\n",
    "\n",
    "print(find_document_frequency(data, target_word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "target_word = 'человек'\n",
    "df, chapter_count = {}, 0\n",
    "chapter = {}\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        chapter = {}\n",
    "        chapter_count += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "        df[word] = df.get(word, 0) + 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "print(df[target_word] / chapter_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3\n",
    "Сделаем следущий шаг: посчитаем частоту употребления отдельного слова в документе (term frequency, или tf). Проще всего объяснить, что такое term frequency, на примере: tf слова война = количество раз, когда слово война встречается в тексте главы / количество всех слов в тексте главы. Попробуем посчитать частоту употребления слова гостья в (15)-й главе (кстати, у нас главы нумеруются с (0)). Слово гостья встречается в (15)-й главе (10) раз, а общее количество слов — (1359).\n",
    "\n",
    "tf слова гостья в (15) главе = (101359 = 0.007358351729212656). Задание. Напишите программу, которая выведет частоту употребления заданного слова target_word = 'человек' в заданной главе target_chapter = 15.\n",
    "\n",
    "Не забудьте добавить в начало своего кода функцию для чтения текста произведения:\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Введите свое решение ниже\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "target_word = 'человек'\n",
    "target_chapter = 15\n",
    "\n",
    "\n",
    "def find_term_frequency(data, target_word, target_chapter):\n",
    "    words_count = 0\n",
    "    target_word_count = 0\n",
    "    chapter = 0\n",
    "    for word in data:\n",
    "        if word == '[new chapter]':\n",
    "            chapter += 1\n",
    "            \n",
    "        if chapter != target_chapter:\n",
    "            continue\n",
    "            \n",
    "        words_count += 1\n",
    "            \n",
    "        if word == target_word:\n",
    "            target_word_count += 1\n",
    "        \n",
    "    \n",
    "    return target_word_count / (words_count-1)\n",
    "\n",
    "\n",
    "print(find_term_frequency(data, target_word, target_chapter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "target_word = 'человек'\n",
    "target_chapter = 15\n",
    "chapter, count, chapter_count = {}, 0, 0\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        if chapter_count == target_chapter:\n",
    "            print(chapter[target_word] / count)\n",
    "        chapter, count = {}, 0\n",
    "        chapter_count += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4\n",
    "Входные данные:\n",
    "\n",
    "строка target_word\n",
    "число target_chapter\n",
    "Пришло время дать разъяснения: для чего мы делали вычисления выше и что нас ждет впереди?\n",
    "\n",
    "Если какое-то слово часто употребляется в документе, то, вероятно, этот документ что-то рассказывает о предмете/действии, описываемом этим словом. Скажем, если вы читаете книгу, в которой много раз употребляется слово заяц, то, вероятно, эта книга про зайцев. Однако, если вы возьмёте слово и, то оно будет встречаться почти в каждой книге много раз. Таким образом, если мы хотим найти наиболее значимые слова в книге, мы, с одной стороны, хотим найти наиболее частые слова, а с другой — убрать те, которые не несут важной информации, так как встречаются везде.\n",
    "\n",
    "Подсказка. Такая задача хорошо решается с помощью tfidf — статистической метрики для оценки важности слова в тексте. Другими словами, tfidf — это «контрастность» слова в документе (насколько оно выделяется среди других слов).\n",
    "\n",
    "tf*idf = term frequency * inverse document frequency tf — это частотность термина, которая измеряет, насколько часто термин встречается в документе. idf — это обратная документная частотность термина. Она измеряет непосредственно важность термина во всём множестве документов.\n",
    "\n",
    "Чтобы получить idf, необходимо поделить (1) на полученную в Задании 2 документную частоту (df).\n",
    "\n",
    "Мы будем использовать не сырые значения tf и idf, а их логарифмы, то есть log(1+tf) * log(idf). Сейчас мы не будем заострять внимание на том, почему следует использовать именно логарифмы — это долгий разговор. Поговорим об этом в курсе Математика и алгоритмы для машинного обучения.\n",
    "\n",
    "В качестве примера измерим tf*idf слова анна в главе (4). Слово анна встречается в указанной главе (7) раз (tf), при этом в (4) главе (1060) слов (chapter_size), всего же слово анна упоминается в (32) главах (df) из (171) (chapter_count).\n",
    "\n",
    "Таким образом, tf*idf данного слова в данной главе будет равно math.log(1+tf/chapter_size) * math.log(1 / df), то есть (0.011031063403921838).\n",
    "\n",
    "Задание. Напишите программу, которая выведет значение tf*idf для заданного слова target_word = 'анна' в заданной главе target_chapter=4.\n",
    "\n",
    "Не забудьте добавить в начало своего кода функцию для чтения текста произведения:\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Введите свое решение ниже\n",
    "import math\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "\n",
    "target_word = 'анна'\n",
    "target_chapter = 4\n",
    "\n",
    "df, chapter_count = {}, 0\n",
    "chapter = {}\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        chapter = {}\n",
    "        chapter_count += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "        df[word] = df.get(word, 0) + 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "\n",
    "        \n",
    "document_frequency = df[target_word] / chapter_count\n",
    "idf = math.log(1 / document_frequency)\n",
    "\n",
    "chapter, count, chapter_count = {}, 0, 0\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        if chapter_count == target_chapter:\n",
    "            term_frequency = chapter[target_word] / count\n",
    "            meet_word = chapter[target_word]\n",
    "            total_count_word = count\n",
    "        chapter, count = {}, 0\n",
    "        chapter_count += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "    count += 1\n",
    "\n",
    "\n",
    "tf_idf = math.log(1 + term_frequency) * math.log(1 / document_frequency)\n",
    "print(tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "\n",
    "target_word = 'анна'\n",
    "target_chapter = 4\n",
    "\n",
    "df, chapter_count = {}, 0\n",
    "chapter = {}\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        chapter = {}\n",
    "        chapter_count += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "        df[word] = df.get(word, 0) + 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "chapter, count, current_chapter = {}, 0, 0\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        if target_chapter == current_chapter:\n",
    "            print(math.log(1 + chapter[target_word] / count) * math.log(chapter_count / df[target_word]))\n",
    "        chapter, count = {}, 0\n",
    "        current_chapter += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5\n",
    "Теперь, когда мы умеем вычислять tf*idf для каждого слова в главе, мы можем найти те слова, которые являются самыми «контрастными» для данной главы, то есть они могут являться в своём роде заголовком для главы.\n",
    "\n",
    "Задача: напишите код, который выведет на экран через пробел три слова, имеющие самое высокое значение tfidf в заданной главе target_chapter = 4 в порядке убывания tfidf. Например, для главы (4) ответом будет: павловна анна тетушку\n",
    "\n",
    "Не забудьте добавить в начало своего кода функцию для чтения текста произведения:\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Введите свое решение ниже\n",
    "import math\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "\n",
    "target_word = 'анна'\n",
    "target_chapter = 4\n",
    "\n",
    "df, chapter_count = {}, 0\n",
    "chapter = {}\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        chapter = {}\n",
    "        chapter_count += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "        df[word] = df.get(word, 0) + 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "        \n",
    "        \n",
    "chapter, count, current_chapter = {}, 0, 0\n",
    "chapter_tf_idf = {}\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        if target_chapter == current_chapter:\n",
    "            for target_word in chapter:\n",
    "                chapter_tf_idf[target_word] = math.log(1 + chapter[target_word] / count) * math.log(chapter_count / df[target_word])\n",
    "#            print(math.log(1 + chapter[target_word] / count) * math.log(chapter_count / df[target_word]))\n",
    "#            print(chapter)\n",
    "#            print(chapter_tf_idf)\n",
    "        chapter, count = {}, 0\n",
    "        current_chapter += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "    count += 1\n",
    "\n",
    "soryed_chapter_tf_idf = sorted(chapter_tf_idf.items(), key=lambda x: x[1], reverse=True)\n",
    "print(soryed_chapter_tf_idf[0][0], soryed_chapter_tf_idf[1][0], soryed_chapter_tf_idf[2][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "data = read_data()\n",
    "target_chapter = 4\n",
    "\n",
    "df, chapter_count = {}, 0\n",
    "chapter = {}\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        chapter = {}\n",
    "        chapter_count += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "        df[word] = df.get(word, 0) + 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "chapter, count, current_chapter = {}, 0, 0\n",
    "for word in data + ['[new chapter]']:\n",
    "    if word == '[new chapter]':\n",
    "        if current_chapter == target_chapter:\n",
    "            words = []\n",
    "            for w in chapter:\n",
    "                words.append((w, chapter[w], df[w], -math.log(1 + chapter[w] / count) * math.log(chapter_count / df[w])))\n",
    "                #words.append((w, chapter[w], df[w], -chapter[w] / count * chapter_count / df[w]))\n",
    "            words = sorted(words, key = itemgetter(3))\n",
    "            print(' '.join([w[0] for w in words[:3]]))\n",
    "        chapter, count = {}, 0\n",
    "        current_chapter += 1\n",
    "        continue\n",
    "    if word not in chapter:\n",
    "        chapter[word] = 1\n",
    "    else:\n",
    "        chapter[word] += 1\n",
    "    count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
